[
  {
    "title": "SpeechCARE: dynamic multimodal modeling for cognitive screening in diverse linguistic and speech task contexts",
    "authors": "Hossein Azadmaleki, Yasaman Haghbin, Sina Rashidi, Mohammad Javad Momeni Nezhad, Ali Zolnour & Maryam Zolnoori",
    "venue": " npj digital medicine ",
    "year": 2025,
    "month": 11,
    "type": "Journal Article",
    "link": "https://www.nature.com/articles/s41746-025-02026-x",
    "image": "/images/publications/speechCARE.png",
    "challenge": "Early detection of cognitive impairment from speech is difficult because available datasets are small, noisy, multilingual, and collected from inconsistent speech tasks. Traditional acoustic features and general-purpose models often fail to capture subtle linguistic and acoustic cues needed to identify Mild Cognitive Impairment (MCI) and Alzheimer’s disease.",
    "solution": "SpeechCARE introduces a dynamic multimodal transformer pipeline that integrates: <ul><li>Advanced preprocessing (LLM-based noise/anomaly detection, speech-task identification, ASR transcription). </li> <li>Multimodal modeling combining acoustic (mHuBERT), linguistic (mGTE), and demographic features.</li> <li>A novel Adaptive Gating Fusion (AGF) mechanism that weights modalities differently depending on the speech task.</li></ul> This architecture captures long-range speech patterns and adapts across languages and task types.",
    "result": "72.11% average F1-score and 86.83% AUC on the NIA PREPARE test set (English, Spanish, Mandarin). <ul> <li>Improved MCI detection through threshold optimization. </li> <li>Top-tier performance in the NIA challenge, earning special recognition. <li>Strong external generalization:<ul class='list-disc pl-5'><li>85.08% F1-score on ADReSSo 2021.</li><li>92.67% AUC / 85.47% F1-score when fine-tuned on Mandarin (Chou Corpus).</li></ul></li></ul>"
  },
  {
    "title": "LLMCARE: early detection of cognitive impairment via transformer models enhanced by LLM-generated synthetic data",
    "authors": "Ali Zolnour, Hossein Azadmaleki, Yasaman Haghbin, Fatemeh Taherinezhad, Mohamad Javad Momeni Nezhad, Sina Rashidi, Masoud Khani, AmirSajjad Taleban, Samin Mahdizadeh Sani, Maryam Dadkhah, James M. Noble, Suzanne Bakken, Yadollah Yaghoobzadeh, Abdol-Hossein Vahabie, Masoud Rouhizadeh, Maryam Zolnoori",
    "venue": "Frontiers in Artificial Intelligence",
    "year": 2025,
    "month": 11,
    "type": "Journal Article",
    "link": "https://www.frontiersin.org/journals/artificial-intelligence/articles/10.3389/frai.2025.1669896/full",
    "image": "/images/publications/LLMCARE.jpg",
    "challenge": "Speech-based Alzheimer’s screening is limited by scarce labeled clinical speech data, inconsistent model performance across fine-tuning strategies, and poor generalizability across populations and datasets. Prior synthetic data approaches also show mixed results, making it difficult to build reliable and scalable early-screening tools.",
    "solution": "LLMCARE introduces a multi-component Alzheimer’s screening pipeline that integrates:<ul><li><strong>Transformer-based linguistic modeling:</strong> Systematic evaluation of 10 transformer models (general-purpose and clinical-domain) with multiple fine-tuning strategies to capture disfluencies, syntactic irregularities, and semantic drift common in cognitive impairment.</li> <li><strong>Handcrafted linguistic biomarkers:</strong> 110 features covering lexical richness, syntactic complexity, discourse fluency, and psycholinguistic categories to enhance interpretability and complement deep embeddings.</li> <li><strong>Late-fusion architecture:</strong> A learnable weighted fusion layer combining transformer embeddings with handcrafted features to improve robustness and generalization.</li> <li><strong>LLM-generated synthetic speech:</strong> Fine-tuned LLaMA, MedAlpaca, Ministral, and GPT-4o models generate label-conditioned transcripts that emulate cognitively healthy vs. impaired speech for controlled data augmentation.</li> <li><strong>LLMs as classifiers:</strong> Evaluation of unimodal (text-only) and multimodal (audio+text) LLMs in zero-shot and fine-tuned settings to benchmark modern generative models for dementia detection.</li> <li><strong>External generalization:</strong> Validation on the DementiaBank Delaware MCI cohort demonstrates transferability beyond the ADReSSo benchmark and supports clinical screening potential.</li></ul>This architecture strengthens linguistic signal extraction, improves classification performance through aligned synthetic augmentation, and generalizes to early-stage cognitive impairment.",
    "result": "LLMCARE achieved:<ul> <li><strong>ADReSSo 2021:</strong> F1 = <strong>83.32 ± 2.78</strong>, AUC = <strong>89.48 ± 4.40</strong> using the fusion model.</li> <li><strong>Delaware MCI Cohort:</strong> F1 = <strong>72.82</strong>, AUC = <strong>69.57</strong> with 1× MedAlpaca-7B augmentation.</li> <li><strong>Augmentation effects:</strong> MedAlpaca-7B improved performance up to 2× synthetic data (peak F1 ≈ <strong>85.7</strong>).</li> <li><strong>Transformer evaluation:</strong> BERT achieved the highest F1 (82.76 ± 4.51) among general-purpose models.</li> <li><strong>External LLM benchmark:</strong> LLaMA, GPT-4o, and Phi-4 multimodal models show strong viability for dementia detection.</li> </ul> Overall, LLMCARE demonstrates that combining transformer models, handcrafted linguistic features, and aligned LLM-generated narratives yields strong and generalizable performance for early-stage cognitive impairment screening."
  },
  {
    "title": "Speech-Based Cognitive Screening: A Systematic Evaluation of LLM Adaptation Strategies",
    "authors": "Fatemeh Taherinezhad, Mohamad Javad Momeni Nezhad, Sepehr Karimi, Sina Rashidi, Ali Zolnour, Maryam Dadkhah, Yasaman Haghbin, Hossein AzadMaleki, Maryam Zolnoori",
    "venue": "JMIR",
    "year": 2025,
    "month": 8,
    "type": "Under Review",
    "link": "https://arxiv.org/abs/2509.03525",
    "image": "/images/publications/CDS.png",
    "challenge": "…",
    "solution": "…",
    "result": "…"
  },
  {
    "title": "Detecting Mild Cognitive Impairment Using Follow-Up Call Speech and Electronic Health Record Data in Home Health Care Settings",
    "authors": "Maryam Zolnoori, Ali Zolnour, Sina Rashidi, Ian Spens, Yasaman Haghbin, Sasha Vergez, Grace Flaherty, Nicole Onorato, Felix Vasquez, James M. Noble and Margaret McDonald",
    "venue": "Journal of Gerontological Nursing",
    "year": 2025,
    "month": 12,
    "type": "Journal Article",
    "link": "",
    "image": "",
    "challenge": "…",
    "solution": "…",
    "result": "…"
  },
  {
    "title": "Multimodal Attention Fusion of Speech and EHR Data for Early Detection of Cognitive Decline in Home Healthcare",
    "authors": "Yasaman Haghbin*, Sina Rashidi*, Margaret McDonald, Maryam Zolnoori",
    "venue": "ICASSP 2026",
    "year": 2026,
    "month": 4,
    "type": "Under Review",
    "image": "/images/publications/BIMS.svg",
    "challenge": "…",
    "solution": "…",
    "result": "…"
  },
  {
    "title": "Leveraging Text-To-Speech and Voice Conversion as Data Augmentation for Alzheimer's Disease Detection from Spontaneous Speech",
    "authors": "Sina Rashidi, Yasaman Haghbin, Hossein AzadMaleki, Ali Zolnour, Maryam Zolnoori",
    "venue": "ICASSP 2026",
    "year": 2026,
    "month": 4,
    "type": "Under Review",
    "image": "/images/publications/SpeechCURA.svg",
    "challenge": "…",
    "solution": "…",
    "result": "…"
  },
  {
    "title": "Explainability",
    "authors": "Maryam Zolnoori",
    "year": 2026,
    "type": "In Preparation",
    "image": "",
    "challenge": "…",
    "solution": "…",
    "result": "…"
  }
]